{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9966952,"sourceType":"datasetVersion","datasetId":6131367},{"sourceId":10379165,"sourceType":"datasetVersion","datasetId":6429452}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport datasets\nfrom torch.utils.data import DataLoader\n\n# Define constants\nmsmarco_path = \"/kaggle/input/ms-marco-hr/ms-marco-translated.csv\"\nwiki_path = \"/kaggle/input/wiki-cro/wiki-cro.csv\"\n\n# Load datasets\nmsmarco_df = pd.read_csv(msmarco_path)\nwiki_df = pd.read_csv(wiki_path)\n\nmsmarco_df = msmarco_df.rename(columns={\"finalpassage_cro\": \"passage\", \"query_cro\": \"query\", \"query\": \"query_eng\"})\nwiki_df = wiki_df.rename(columns={\"Query\": \"query\", \"Summary\": \"passage\"})\n\n# Select only the new columns\nmsmarco_df = msmarco_df[[\"query\", \"passage\"]]\nwiki_df = wiki_df[[\"query\", \"passage\"]]\n\ncombined_df = pd.concat([msmarco_df, wiki_df], ignore_index=True)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-05T16:35:20.821608Z","iopub.execute_input":"2025-01-05T16:35:20.821993Z","iopub.status.idle":"2025-01-05T16:35:21.187568Z","shell.execute_reply.started":"2025-01-05T16:35:20.821960Z","shell.execute_reply":"2025-01-05T16:35:21.186431Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Convert to Hugging Face Dataset\nds = datasets.arrow_dataset.Dataset.from_pandas(combined_df)\nds = ds.filter(lambda example: example[\"passage\"] is not None and example[\"query\"] is not None)\n\n# Split the dataset\nseed = 42\n_train_val, test_ds = ds.train_test_split(test_size=0.1, seed=seed).values()\ntrain_ds, val_ds = _train_val.train_test_split(test_size=0.1111, seed=seed).values()\n\n# Save splits to CSV\ntrain_ds.to_csv(\"train.csv\", index=False)\nval_ds.to_csv(\"val.csv\", index=False)\ntest_ds.to_csv(\"test.csv\", index=False)\n\nprint(len(train_ds), len(val_ds), len(test_ds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T16:35:21.188756Z","iopub.execute_input":"2025-01-05T16:35:21.189099Z","iopub.status.idle":"2025-01-05T16:35:22.200294Z","shell.execute_reply.started":"2025-01-05T16:35:21.189069Z","shell.execute_reply":"2025-01-05T16:35:22.199125Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb004bc11aeb489ea0a2622f8a1d235c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a612d39a73f44abb807ca0e4bfe41639"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7de8644ab4c8408ea1cfba92ceda579f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating CSV from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b22471b3606c4bbd87cc96910e141e16"}},"metadata":{}},{"name":"stdout","text":"15879 1985 1985\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Load splits from CSV\ntrain_df = pd.read_csv(\"train.csv\")\ntest_df = pd.read_csv(\"test.csv\")\n\n# Create DataLoaders (if required)\ntrain_dataloader = DataLoader(train_df, batch_size=32, shuffle=True)\ntest_dataloader = DataLoader(test_df, batch_size=32, shuffle=False)\n\nprint(\"Data pipeline completed successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T16:35:22.201978Z","iopub.execute_input":"2025-01-05T16:35:22.202243Z","iopub.status.idle":"2025-01-05T16:35:22.414671Z","shell.execute_reply.started":"2025-01-05T16:35:22.202219Z","shell.execute_reply":"2025-01-05T16:35:22.413476Z"}},"outputs":[{"name":"stdout","text":"Data pipeline completed successfully.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}